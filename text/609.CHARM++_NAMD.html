

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>CHARM++ and NAMD &mdash; WVU-RC 1.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Density Functional Theory" href="610.DFT.html" />
    <link rel="prev" title="Force Field Molecular Dynamics" href="608.ForceFields.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> WVU-RC
          

          
            
            <img src="../_static/ResearchComputing.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="10.Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="20.QuickStart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="30.BasicUser.html">For Basic Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="40.AdvancedUser.html">For Advanced Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="50.ProgrammingLanguages.html">Programming Languages</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="600.SoftAdmin.html">Software Administration</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="601.SphinxDocs.html">Editing these documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="602.UserInstallation.html">Installing Packages in User Locations</a></li>
<li class="toctree-l2"><a class="reference internal" href="603.LinearAlgebra.html">Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="604.Boost.html">Boost 1.77</a></li>
<li class="toctree-l2"><a class="reference internal" href="605.MPI.html">Message Passing Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="606.HDF5_NetCDF.html">HDF5 and NetCDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="607.FFT.html">Fast Fourier Transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="608.ForceFields.html">Force Field Molecular Dynamics</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">CHARM++ and NAMD</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#compiling-charm">Compiling Charm++</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-namd2">Compiling NAMD2</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quick-test-namd2-for-alanin">Quick test NAMD2 for Alanin</a></li>
<li class="toctree-l3"><a class="reference internal" href="#script-summarizing-compilation-of-namd">Script summarizing compilation of NAMD</a></li>
<li class="toctree-l3"><a class="reference internal" href="#benchmarking-namd2">Benchmarking NAMD2</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conclusions">Conclusions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="610.DFT.html">Density Functional Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="611.BigData.html">Big Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="612.Python.html">Python 3.9.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="70.DomainSpecific.html">Domain Specific Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="80.ClusterSpecific.html">Clusters Specifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="90.References.html">References</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">WVU-RC</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="600.SoftAdmin.html">Software Administration</a> &raquo;</li>
        
      <li>CHARM++ and NAMD</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/text/609.CHARM++_NAMD.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="charm-and-namd">
<h1>CHARM++ and NAMD<a class="headerlink" href="#charm-and-namd" title="Permalink to this headline">¶</a></h1>
<p>NAMD is a computer software for classical molecular dynamics simulation, written using the Charm++ parallel programming model. It is noted for its parallel efficiency and is often used to simulate large systems (millions of atoms). It has been developed by the collaboration of the Theoretical and Computational Biophysics Group (TCB) and the Parallel Programming Laboratory (PPL) at the University of Illinois at Urbana–Champaign.</p>
<p>The purpose of this document is to show how Charm++ and NAMD were compiled on Thorny Flat, a cluster build from Skylake CPUs. The current stable sources 2.13 fail compilation using OFI network library. For that reason we will be using the Nightly archived sources available on the official NAMD site.</p>
<p>The sources can be downloaded for the most recent date at the moment of download. The sources can be download using this command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>VERSION=2021-10-05
wget https://www.ks.uiuc.edu/Research/namd/cvs/download/741376/NAMD_Git-${VERSION}_Source.tar.gz
</pre></div>
</div>
<p>This is the current Nightly build by the time of writing this document
(2020-01-02). The nightly build can be downloaded from the browser on
<a class="reference external" href="https://www.ks.uiuc.edu/Development/Download/download.cgi?PackageName=NAMD">https://www.ks.uiuc.edu/Development/Download/download.cgi?PackageName=NAMD</a></p>
<p>The sources are archived in a tar and compressed file. Untar and uncompress them. Go into the created folder and untar the charm sources too:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>tar -zxvf NAMD_Git-${VERSION}_Source.tar.gz
cd NAMD_Git-${VERSION}_Source/
tar -xvf charm-6.10.2.tar
</pre></div>
</div>
<p>We will compile Charm and NAMD using the Intel Compilers 2021, the latest version at the moment of writing this document:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">purge</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">compiler</span><span class="o">/</span><span class="mf">2021.2</span><span class="o">.</span><span class="mi">0</span> <span class="n">mkl</span><span class="o">/</span><span class="mf">2021.2</span><span class="o">.</span><span class="mi">0</span> <span class="n">mpi</span><span class="o">/</span><span class="mf">2021.2</span><span class="o">.</span><span class="mi">0</span>
</pre></div>
</div>
<div class="section" id="compiling-charm">
<h2>Compiling Charm++<a class="headerlink" href="#compiling-charm" title="Permalink to this headline">¶</a></h2>
<p>We start compiling charm++, go into the <code class="docutils literal notranslate"><span class="pre">charm-6.10.2</span></code> folder:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">charm</span><span class="o">-</span><span class="mf">6.10</span><span class="o">.</span><span class="mi">2</span>
</pre></div>
</div>
<p>We will compile 4 versions. The MPI version and the OFI version for both single threaded and shared memory versions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">MPICXX</span><span class="o">=</span><span class="n">mpiicpc</span> <span class="o">./</span><span class="n">build</span> <span class="n">charm</span><span class="o">++</span> <span class="n">mpi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span> <span class="n">mpicxx</span> <span class="n">ifort</span> <span class="o">-</span><span class="n">j12</span> <span class="o">--</span><span class="k">with</span><span class="o">-</span><span class="n">production</span>

<span class="n">MPICXX</span><span class="o">=</span><span class="n">mpiicpc</span> <span class="o">./</span><span class="n">build</span> <span class="n">charm</span><span class="o">++</span> <span class="n">mpi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span> <span class="n">mpicxx</span> <span class="n">ifort</span> <span class="n">smp</span> <span class="o">-</span><span class="n">j12</span> <span class="o">--</span><span class="k">with</span><span class="o">-</span><span class="n">production</span>

<span class="o">./</span><span class="n">build</span> <span class="n">charm</span><span class="o">++</span> <span class="n">ofi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span> <span class="n">icc</span> <span class="n">ifort</span> <span class="o">-</span><span class="n">j12</span> <span class="o">--</span><span class="k">with</span><span class="o">-</span><span class="n">production</span>

<span class="o">./</span><span class="n">build</span> <span class="n">charm</span><span class="o">++</span> <span class="n">ofi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span> <span class="n">icc</span> <span class="n">ifort</span> <span class="n">smp</span> <span class="o">-</span><span class="n">j12</span> <span class="o">--</span><span class="k">with</span><span class="o">-</span><span class="n">production</span>
</pre></div>
</div>
<p>Executing those 4 commands will compile charm++ in a variety of ways that take
advantage of Intel Omni-Path. The <code class="docutils literal notranslate"><span class="pre">smp</span></code> version takes one extra thread for managing communication reducing the amount of usable cores but allows to share memory efficiently allowing for computations with larger systems. That is why having the <code class="docutils literal notranslate"><span class="pre">smp</span></code> and <code class="docutils literal notranslate"><span class="pre">non-smp</span></code> versions is recommended.</p>
<p>You can test those 4 compilations of charm++ with the testsuite provided with the sources. Notice that before each new tests the previous binaries must be deleted. The following commands will perform the 4 tests suite runs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">mpi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">tests</span><span class="o">/</span><span class="n">charm</span><span class="o">++</span>
<span class="n">make</span> <span class="n">clean</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="n">test</span>
<span class="n">cd</span> <span class="o">../../..</span>
<span class="n">cd</span> <span class="n">mpi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">tests</span><span class="o">/</span><span class="n">charm</span><span class="o">++</span>
<span class="n">make</span> <span class="n">clean</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="n">test</span>
<span class="n">cd</span> <span class="o">../../..</span>
<span class="n">cd</span> <span class="n">ofi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">tests</span><span class="o">/</span><span class="n">charm</span><span class="o">++</span>
<span class="n">make</span> <span class="n">clean</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="n">test</span>
<span class="n">cd</span> <span class="o">../../..</span>
<span class="n">cd</span> <span class="n">ofi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">tests</span><span class="o">/</span><span class="n">charm</span><span class="o">++</span>
<span class="n">make</span> <span class="n">clean</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="n">test</span>
<span class="n">cd</span> <span class="o">../../..</span>
<span class="n">cd</span> <span class="n">ofi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">tests</span><span class="o">/</span><span class="n">charm</span><span class="o">++</span>
<span class="n">make</span> <span class="n">clean</span> <span class="o">&amp;&amp;</span> <span class="n">make</span>
<span class="n">cd</span> <span class="n">megatest</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="o">&amp;&amp;</span> <span class="n">make</span> <span class="n">test</span>
<span class="n">cd</span> <span class="o">../../../..</span>
</pre></div>
</div>
<p>The last case is a bit different as one test fail with smp.
We should now return to the NAMD sources to continue the compilation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">..</span>
</pre></div>
</div>
</div>
<div class="section" id="compiling-namd2">
<h2>Compiling NAMD2<a class="headerlink" href="#compiling-namd2" title="Permalink to this headline">¶</a></h2>
<p>Now we proceed to compile NAMD.
Download and install TCL and FFTW libraries asuming that you are now on the root folder for NAMD sources:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">ks</span><span class="o">.</span><span class="n">uiuc</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">Research</span><span class="o">/</span><span class="n">namd</span><span class="o">/</span><span class="n">libraries</span><span class="o">/</span><span class="n">fftw</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">tar</span> <span class="n">xzf</span> <span class="n">fftw</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">mv</span> <span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span> <span class="n">fftw</span>
<span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">ks</span><span class="o">.</span><span class="n">uiuc</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">Research</span><span class="o">/</span><span class="n">namd</span><span class="o">/</span><span class="n">libraries</span><span class="o">/</span><span class="n">tcl8</span><span class="o">.</span><span class="mf">5.9</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">ks</span><span class="o">.</span><span class="n">uiuc</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">Research</span><span class="o">/</span><span class="n">namd</span><span class="o">/</span><span class="n">libraries</span><span class="o">/</span><span class="n">tcl8</span><span class="o">.</span><span class="mf">5.9</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">threaded</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">tar</span> <span class="n">xzf</span> <span class="n">tcl8</span><span class="o">.</span><span class="mf">5.9</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">tar</span> <span class="n">xzf</span> <span class="n">tcl8</span><span class="o">.</span><span class="mf">5.9</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">threaded</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">mv</span> <span class="n">tcl8</span><span class="o">.</span><span class="mf">5.9</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span> <span class="n">tcl</span>
<span class="n">mv</span> <span class="n">tcl8</span><span class="o">.</span><span class="mf">5.9</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">threaded</span> <span class="n">tcl</span><span class="o">-</span><span class="n">threaded</span>
</pre></div>
</div>
<p>The next step is to edit the file <code class="docutils literal notranslate"><span class="pre">Make.charm</span></code> to edit the variable <code class="docutils literal notranslate"><span class="pre">CHARMBASE</span></code>. Another option is to create a symbolic link called <code class="docutils literal notranslate"><span class="pre">charm</span></code> pointing to the location of the charm sources, like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ln</span> <span class="o">-</span><span class="n">s</span> <span class="n">charm</span><span class="o">-</span><span class="mf">6.10</span><span class="o">.</span><span class="mi">2</span> <span class="n">charm</span>
</pre></div>
</div>
<p>The configuration of NAMD is done via a text file located at the <code class="docutils literal notranslate"><span class="pre">arch</span></code> folder. Create the following files with the commands:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>cat &lt;&lt; EOF &gt; arch/Linux-x86_64-mpi-mpicxx.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = mpi-linux-x86_64-ifort-mpicxx

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF

cat &lt;&lt; EOF &gt; arch/Linux-x86_64-mpi-smp-mpicxx.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = mpi-linux-x86_64-ifort-smp-mpicxx

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF

cat &lt;&lt; EOF &gt; arch/Linux-x86_64-ofi-icc.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = ofi-linux-x86_64-ifort-icc

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF

cat &lt;&lt; EOF &gt; arch/Linux-x86_64-ofi-smp-icc.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = ofi-linux-x86_64-ifort-smp-icc

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF
</pre></div>
</div>
<p>Executing the code above will produce 4 files with the following contents.</p>
<p>File <code class="docutils literal notranslate"><span class="pre">Linux-x86_64-mpi-mpicxx.arch</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>NAMD_ARCH = Linux-x86_64
CHARMARCH = mpi-linux-x86_64-ifort-mpicxx

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 $(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias $(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 $(FLOATOPTS)
</pre></div>
</div>
<p>File <code class="docutils literal notranslate"><span class="pre">Linux-x86_64-mpi-smp-mpicxx.arch</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>NAMD_ARCH = Linux-x86_64
CHARMARCH = mpi-linux-x86_64-ifort-smp-mpicxx

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 $(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias $(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 $(FLOATOPTS)
</pre></div>
</div>
<p>File <code class="docutils literal notranslate"><span class="pre">Linux-x86_64-ofi-icc.arch</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>NAMD_ARCH = Linux-x86_64
CHARMARCH = ofi-linux-x86_64-ifort-icc

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 $(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias $(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 $(FLOATOPTS)
</pre></div>
</div>
<p>File <code class="docutils literal notranslate"><span class="pre">Linux-x86_64-ofi-smp-icc.arch</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>NAMD_ARCH = Linux-x86_64
CHARMARCH = ofi-linux-x86_64-ifort-smp-icc

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 $(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias $(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 $(FLOATOPTS)
</pre></div>
</div>
<p>To compile NAMD, the corresponding building folder must be created via the config command. The following commands will create 4 folders for the corresponding versions of charm++ that we will use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">config</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">mpicxx</span> <span class="o">--</span><span class="n">charm</span><span class="o">-</span><span class="n">arch</span> <span class="n">mpi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">mpicxx</span>
<span class="o">./</span><span class="n">config</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span> <span class="o">--</span><span class="n">charm</span><span class="o">-</span><span class="n">arch</span> <span class="n">mpi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span>
<span class="o">./</span><span class="n">config</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">icc</span> <span class="o">--</span><span class="n">charm</span><span class="o">-</span><span class="n">arch</span> <span class="n">ofi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">icc</span>
<span class="o">./</span><span class="n">config</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span> <span class="o">--</span><span class="n">charm</span><span class="o">-</span><span class="n">arch</span> <span class="n">ofi</span><span class="o">-</span><span class="n">linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ifort</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span>
</pre></div>
</div>
<p>Now we can go inside each folder and compile the code with <code class="docutils literal notranslate"><span class="pre">make</span></code>. To speed up the compilation, 12 execution lines will be used:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">mpicxx</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j12</span>
<span class="n">cd</span> <span class="o">..</span>
<span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j12</span>
<span class="n">cd</span> <span class="o">..</span>
<span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">icc</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j12</span>
<span class="n">cd</span> <span class="o">..</span>
<span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j12</span>
<span class="n">cd</span> <span class="o">..</span>
</pre></div>
</div>
<p>At the end of those compilations we will have 4 versions of the command <code class="docutils literal notranslate"><span class="pre">namd2</span></code>. However, due to a bug on Intel’s <code class="docutils literal notranslate"><span class="pre">opa-psm2</span></code> the NAMD binaries will return an error when executed. The error looks similar to this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">mmap</span> <span class="n">of</span> <span class="n">status</span> <span class="n">page</span> <span class="p">(</span><span class="n">dabbad0008030000</span><span class="p">)</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Operation</span> <span class="ow">not</span> <span class="n">permitted</span>
</pre></div>
</div>
<p>For the particular case of Thorny, executing NAMD will return (MPI version):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">mmap</span> <span class="n">of</span> <span class="n">status</span> <span class="n">page</span> <span class="p">(</span><span class="n">dabbad00080b0000</span><span class="p">)</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Operation</span> <span class="ow">not</span> <span class="n">permitted</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">hfp_gen1_context_open</span><span class="p">:</span> <span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">failed</span><span class="p">,</span> <span class="n">trying</span> <span class="n">again</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">assign_context</span> <span class="n">command</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Invalid</span> <span class="n">argument</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">hfp_gen1_context_open</span><span class="p">:</span> <span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">failed</span><span class="p">,</span> <span class="n">trying</span> <span class="n">again</span> <span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">assign_context</span> <span class="n">command</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Invalid</span> <span class="n">argument</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">hfp_gen1_context_open</span><span class="p">:</span> <span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">failed</span><span class="p">,</span> <span class="n">trying</span> <span class="n">again</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">assign_context</span> <span class="n">command</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Invalid</span> <span class="n">argument</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26685</span><span class="n">PSM2</span> <span class="n">can</span><span class="s1">&#39;t open hfi unit: -1 (err=23)</span>
<span class="n">Abort</span><span class="p">(</span><span class="mi">1615759</span><span class="p">)</span> <span class="n">on</span> <span class="n">node</span> <span class="mi">0</span> <span class="p">(</span><span class="n">rank</span> <span class="mi">0</span> <span class="ow">in</span> <span class="n">comm</span> <span class="mi">0</span><span class="p">):</span> <span class="n">Fatal</span> <span class="n">error</span> <span class="ow">in</span> <span class="n">PMPI_Init_thread</span><span class="p">:</span> <span class="n">Other</span> <span class="n">MPI</span> <span class="n">error</span><span class="p">,</span> <span class="n">error</span> <span class="n">stack</span><span class="p">:</span>
<span class="n">MPIR_Init_thread</span><span class="p">(</span><span class="mi">703</span><span class="p">)</span><span class="o">........</span><span class="p">:</span>
<span class="n">MPID_Init</span><span class="p">(</span><span class="mi">923</span><span class="p">)</span><span class="o">...............</span><span class="p">:</span>
<span class="n">MPIDI_OFI_mpi_init_hook</span><span class="p">(</span><span class="mi">1211</span><span class="p">):</span>
<span class="n">create_endpoint</span><span class="p">(</span><span class="mi">1892</span><span class="p">)</span><span class="o">........</span><span class="p">:</span> <span class="n">OFI</span> <span class="n">endpoint</span> <span class="nb">open</span> <span class="n">failed</span> <span class="p">(</span><span class="n">ofi_init</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="mi">1892</span><span class="p">:</span><span class="n">create_endpoint</span><span class="p">:</span><span class="n">Invalid</span> <span class="n">argument</span><span class="p">)</span>
</pre></div>
</div>
<p>Or (OFI version):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">provider</span><span class="p">:</span> <span class="n">psm2</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">control</span> <span class="n">progress</span><span class="p">:</span> <span class="mi">2</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">data</span> <span class="n">progress</span><span class="p">:</span> <span class="mi">2</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">maximum</span> <span class="n">inject</span> <span class="n">message</span> <span class="n">size</span><span class="p">:</span> <span class="mi">64</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">eager</span> <span class="n">maximum</span> <span class="n">message</span> <span class="n">size</span><span class="p">:</span> <span class="mi">65536</span> <span class="p">(</span><span class="n">maximum</span> <span class="n">header</span> <span class="n">size</span><span class="p">:</span> <span class="mi">40</span><span class="p">)</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">cq</span> <span class="n">entries</span> <span class="n">count</span><span class="p">:</span> <span class="mi">8</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">use</span> <span class="n">inject</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">maximum</span> <span class="n">rma</span> <span class="n">size</span><span class="p">:</span> <span class="mi">4294967295</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">mr</span> <span class="n">mode</span><span class="p">:</span> <span class="mh">0x1</span>
<span class="n">Charm</span><span class="o">++&gt;</span><span class="n">ofi</span><span class="o">&gt;</span> <span class="n">use</span> <span class="n">memory</span> <span class="n">pool</span><span class="p">:</span> <span class="mi">0</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">mmap</span> <span class="n">of</span> <span class="n">status</span> <span class="n">page</span> <span class="p">(</span><span class="n">dabbad00080b0000</span><span class="p">)</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Operation</span> <span class="ow">not</span> <span class="n">permitted</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">hfp_gen1_context_open</span><span class="p">:</span> <span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">failed</span><span class="p">,</span> <span class="n">trying</span> <span class="n">again</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">assign_context</span> <span class="n">command</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Invalid</span> <span class="n">argument</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">hfp_gen1_context_open</span><span class="p">:</span> <span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">failed</span><span class="p">,</span> <span class="n">trying</span> <span class="n">again</span> <span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">assign_context</span> <span class="n">command</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Invalid</span> <span class="n">argument</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">hfp_gen1_context_open</span><span class="p">:</span> <span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">failed</span><span class="p">,</span> <span class="n">trying</span> <span class="n">again</span> <span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">hfi_userinit</span><span class="p">:</span> <span class="n">assign_context</span> <span class="n">command</span> <span class="n">failed</span><span class="p">:</span> <span class="n">Invalid</span> <span class="n">argument</span>
<span class="n">trcis001</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span><span class="o">.</span><span class="mi">26858</span><span class="n">PSM2</span> <span class="n">can</span><span class="s1">&#39;t open hfi unit: -1 (err=23)</span>
<span class="o">-------</span> <span class="n">Partition</span> <span class="mi">0</span> <span class="n">Processor</span> <span class="mi">0</span> <span class="n">Exiting</span><span class="p">:</span> <span class="n">Called</span> <span class="n">CmiAbort</span> <span class="o">------</span>
<span class="n">Reason</span><span class="p">:</span> <span class="n">OFI</span><span class="p">::</span><span class="n">LrtsInit</span><span class="p">::</span><span class="n">fi_endpoint</span> <span class="n">error</span>
<span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">Stack</span> <span class="n">Traceback</span><span class="p">:</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">0</span><span class="p">]</span> <span class="n">namd2</span> <span class="mh">0x1126347</span> <span class="n">CmiAbortHelper</span><span class="p">(</span><span class="n">char</span> <span class="n">const</span><span class="o">*</span><span class="p">,</span> <span class="n">char</span> <span class="n">const</span><span class="o">*</span><span class="p">,</span> <span class="n">char</span> <span class="n">const</span><span class="o">*</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> <span class="n">namd2</span> <span class="mh">0x11262e7</span> <span class="n">CmiAbort</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="n">namd2</span> <span class="mh">0x1125088</span> <span class="n">LrtsInit</span><span class="p">(</span><span class="nb">int</span><span class="o">*</span><span class="p">,</span> <span class="n">char</span><span class="o">***</span><span class="p">,</span> <span class="nb">int</span><span class="o">*</span><span class="p">,</span> <span class="nb">int</span><span class="o">*</span><span class="p">)</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="n">namd2</span> <span class="mh">0x112664a</span> <span class="n">ConverseInit</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="n">namd2</span> <span class="mh">0x68e302</span> <span class="n">BackEnd</span><span class="p">::</span><span class="n">init</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">char</span><span class="o">**</span><span class="p">)</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span> <span class="n">namd2</span> <span class="mh">0x68332c</span> <span class="n">main</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="n">libc</span><span class="o">.</span><span class="n">so</span><span class="o">.</span><span class="mi">6</span> <span class="mh">0x7fbe439b53d5</span> <span class="n">__libc_start_main</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span> <span class="n">namd2</span> <span class="mh">0x5d9ab9</span>
</pre></div>
</div>
<p>The issue is related to the execute bit being set in the GNU_STACK of the ELF headers in a binary. That in turn attempts to map the memory region with both the read and execute bits enabled, rather than just the read bit as PSM2 is requesting. As described in this post:</p>
<p><a class="reference external" href="https://stackoverflow.com/questions/32730643/why-in-mmap-prot-read-equals-prot-exec">https://stackoverflow.com/questions/32730643/why-in-mmap-prot-read-equals-prot-exec</a></p>
<p>And the solution was posted here:</p>
<p><a class="reference external" href="https://github.com/intel/opa-psm2/issues/29">https://github.com/intel/opa-psm2/issues/29</a></p>
<p>One can inspect a binary for this setting using readelf:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">readelf</span> <span class="o">--</span><span class="n">program</span><span class="o">-</span><span class="n">headers</span> <span class="o">./</span><span class="n">namd2</span>
</pre></div>
</div>
<p>The output from that command will show this for the <code class="docutils literal notranslate"><span class="pre">GNU_STACK</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GNU_STACK</span>      <span class="mh">0x0000000000000000</span> <span class="mh">0x0000000000000000</span> <span class="mh">0x0000000000000000</span>
               <span class="mh">0x0000000000000000</span> <span class="mh">0x0000000000000000</span>  <span class="n">RWE</span>    <span class="mi">10</span>
</pre></div>
</div>
<p>This issue can be fixed over the binaries already created by executing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">execstack</span> <span class="o">-</span><span class="n">c</span> <span class="o">./</span><span class="n">namd2</span>
</pre></div>
</div>
<p>From the NAMD source folder the following command will fix that for the 4 binaries:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">execstack</span> <span class="o">-</span><span class="n">c</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-*/</span><span class="n">namd2</span>
</pre></div>
</div>
</div>
<div class="section" id="quick-test-namd2-for-alanin">
<h2>Quick test NAMD2 for Alanin<a class="headerlink" href="#quick-test-namd2-for-alanin" title="Permalink to this headline">¶</a></h2>
<p>Now we can start testing the 4 binaries of <code class="docutils literal notranslate"><span class="pre">namd2</span></code>.
NAMD offers a very small case for testing on <code class="docutils literal notranslate"><span class="pre">src/alanin</span></code>.
Execute NAMD on each folder to test the binary.
Notice that for the SMP binaries a couple of extra arguments are needed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">mpicxx</span>
<span class="o">./</span><span class="n">charmrun</span> <span class="o">++</span><span class="n">local</span> <span class="o">+</span><span class="n">p2</span> <span class="o">./</span><span class="n">namd2</span> <span class="n">src</span><span class="o">/</span><span class="n">alanin</span>
<span class="n">cd</span> <span class="o">..</span>
<span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">icc</span>
<span class="o">./</span><span class="n">charmrun</span> <span class="o">++</span><span class="n">local</span> <span class="o">+</span><span class="n">p2</span> <span class="o">./</span><span class="n">namd2</span> <span class="n">src</span><span class="o">/</span><span class="n">alanin</span>
<span class="n">cd</span> <span class="o">..</span>
<span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span>
<span class="o">./</span><span class="n">charmrun</span> <span class="o">++</span><span class="n">local</span> <span class="o">+</span><span class="n">p2</span> <span class="o">./</span><span class="n">namd2</span> <span class="n">src</span><span class="o">/</span><span class="n">alanin</span> <span class="o">++</span><span class="n">ppn2</span> <span class="o">+</span><span class="n">setcpuaffinity</span>
<span class="n">cd</span> <span class="o">..</span>
<span class="n">cd</span> <span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span>
<span class="o">./</span><span class="n">charmrun</span> <span class="o">++</span><span class="n">local</span> <span class="o">+</span><span class="n">p2</span> <span class="o">./</span><span class="n">namd2</span> <span class="n">src</span><span class="o">/</span><span class="n">alanin</span> <span class="o">++</span><span class="n">ppn2</span> <span class="o">+</span><span class="n">setcpuaffinity</span>
<span class="n">cd</span> <span class="o">..</span>
</pre></div>
</div>
<p>The MPI-based non-SMP binary is executed as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./charmrun ++local +p2 ./namd2 src/alanin

Running on 2 processors:  ./namd2 src/alanin
charmrun&gt;  /bin/setarch x86_64 -R  mpirun -np 2  ./namd2 src/alanin
Charm++&gt; Running on MPI version: 3.1
Charm++&gt; level of thread support used: MPI_THREAD_SINGLE (desired: MPI_THREAD_SINGLE)
Charm++&gt; Running in non-SMP mode: 2 processes (PEs)
Charm++&gt; Using recursive bisection (scheme 3) for topology aware partitions
Converse/Charm++ Commit ID: v6.10.2-0-g7bf00fa-namd-charm-6.10.2-build-2020-Aug-05-556
CharmLB&gt; Load balancer assumes all CPUs are same.
Charm++&gt; Running on 1 hosts (2 sockets x 12 cores x 2 PUs = 48-way SMP)
Charm++&gt; cpu topology info is gathered in 0.001 seconds.
Info: NAMD Git-2021-10-05 for Linux-x86_64-MPI
...
</pre></div>
</div>
<p>The OFI non-SMP binaries can be tested in a similar way:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./charmrun ++local +p2 ./namd2 src/alanin

Running on 2 processors:  ./namd2 src/alanin
charmrun&gt;  /bin/setarch x86_64 -R  mpirun -np 2  ./namd2 src/alanin
Charm++&gt;ofi&gt; provider: psm2
Charm++&gt;ofi&gt; control progress: 2
Charm++&gt;ofi&gt; data progress: 2
Charm++&gt;ofi&gt; maximum inject message size: 64
Charm++&gt;ofi&gt; eager maximum message size: 65536 (maximum header size: 40)
Charm++&gt;ofi&gt; cq entries count: 8
Charm++&gt;ofi&gt; use inject: 1
Charm++&gt;ofi&gt; maximum rma size: 4294963200
Charm++&gt;ofi&gt; mr mode: 0x1
Charm++&gt;ofi&gt; use memory pool: 0
Charm++&gt;ofi&gt; use request cache: 0
Charm++&gt;ofi&gt; number of pre-allocated recvs: 8
Charm++&gt;ofi&gt; exchanging addresses over OFI
Charm++&gt; Running in non-SMP mode: 2 processes (PEs)
Charm++&gt; Using recursive bisection (scheme 3) for topology aware partitions
Converse/Charm++ Commit ID: v6.10.2-0-g7bf00fa-namd-charm-6.10.2-build-2020-Aug-05-556
CharmLB&gt; Load balancer assumes all CPUs are same.
Charm++&gt; Running on 1 hosts (2 sockets x 12 cores x 2 PUs = 48-way SMP)
Charm++&gt; cpu topology info is gathered in 0.001 seconds.
Info: NAMD Git-2021-10-05 for Linux-x86_64-ofi
...
</pre></div>
</div>
<p>The SMP binaries are special in the arguments needed to run.
The binary at <code class="docutils literal notranslate"><span class="pre">Linux-x86_64-mpi-smp-mpicxx</span></code> needs at least an extra argument <code class="docutils literal notranslate"><span class="pre">++ppn</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./charmrun ++local +p2 ./namd2 src/alanin ++ppn2

Running on 1 processors:  ./namd2 src/alanin ++ppn2
charmrun&gt;  /bin/setarch x86_64 -R  mpirun -np 1  ./namd2 src/alanin ++ppn2
Charm++&gt; Running on MPI version: 3.1
Charm++&gt; level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++&gt; Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++&gt; The comm. thread both sends and receives messages
Charm++&gt; Using recursive bisection (scheme 3) for topology aware partitions
Converse/Charm++ Commit ID: v6.10.2-0-g7bf00fa-namd-charm-6.10.2-build-2020-Aug-05-556
Charm++ communication thread will sleep due to single-process run.
CharmLB&gt; Load balancer assumes all CPUs are same.
Charm++&gt; Running on 1 hosts (2 sockets x 12 cores x 2 PUs = 48-way SMP)
Charm++&gt; cpu topology info is gathered in 0.001 seconds.
Info: NAMD Git-2021-10-05 for Linux-x86_64-MPI-smp
...
</pre></div>
</div>
<p>The OFI SMP binaries <code class="docutils literal notranslate"><span class="pre">Linux-x86_64-ofi-smp-icc</span></code> needs <code class="docutils literal notranslate"><span class="pre">+setcpuaffinity</span></code> because at least one thread for communication and that will oversubscribe the number of worker processes plus one communication thread:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./charmrun ++local +p2 ./namd2 src/alanin ++ppn2 +setcpuaffinity

Running on 1 processors:  ./namd2 src/alanin ++ppn2 +setcpuaffinity
charmrun&gt;  /bin/setarch x86_64 -R  mpirun -np 1  ./namd2 src/alanin ++ppn2 +setcpuaffinity
Charm++&gt;ofi&gt; provider: psm2
Charm++&gt;ofi&gt; control progress: 2
Charm++&gt;ofi&gt; data progress: 2
Charm++&gt;ofi&gt; maximum inject message size: 64
Charm++&gt;ofi&gt; eager maximum message size: 65536 (maximum header size: 40)
Charm++&gt;ofi&gt; cq entries count: 8
Charm++&gt;ofi&gt; use inject: 1
Charm++&gt;ofi&gt; maximum rma size: 4294963200
Charm++&gt;ofi&gt; mr mode: 0x1
Charm++&gt;ofi&gt; use memory pool: 0
Charm++&gt;ofi&gt; use request cache: 0
Charm++&gt;ofi&gt; number of pre-allocated recvs: 8
Charm++&gt;ofi&gt; exchanging addresses over OFI
Charm++&gt; Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++&gt; The comm. thread both sends and receives messages
Charm++&gt; Using recursive bisection (scheme 3) for topology aware partitions
Converse/Charm++ Commit ID: v6.10.2-0-g7bf00fa-namd-charm-6.10.2-build-2020-Aug-05-556
Charm++ communication thread will sleep due to single-process run.
CharmLB&gt; Load balancer assumes all CPUs are same.
Charm++&gt; cpu affinity enabled.
Charm++&gt; Running on 1 hosts (2 sockets x 12 cores x 2 PUs = 48-way SMP)
Charm++&gt; cpu topology info is gathered in 0.013 seconds.
Info: NAMD Git-2021-10-05 for Linux-x86_64-ofi-smp
...
</pre></div>
</div>
<p>The extra argument is needed as multiple PEs get assigned to same core.
Setting +setcpuaffinity will prevent that.</p>
<p>You should not pay much attention to timings for this case. The purpose of the executions above is to proof than NAMD works at least for a simple execution.
The memory used start showing important changes between the 4 binaries:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>11:52:06-build@trcis001:/shared/src/NAMD_Git-2021-10-05_Source/Linux-x86_64-mpi-mpicxx$
WallClock: 0.018382  CPUTime: 0.018382  Memory: 4145.171875 MB

11:52:20-build@trcis001:/shared/src/NAMD_Git-2021-10-05_Source/Linux-x86_64-ofi-icc$
WallClock: 0.019521  CPUTime: 0.016802  Memory: 318.988281 MB

11:52:11-build@trcis001:/shared/src/NAMD_Git-2021-10-05_Source/Linux-x86_64-mpi-smp-mpicxx$
WallClock: 0.019347  CPUTime: 0.015666  Memory: 2610.667969 MB

11:52:01-build@trcis001:/shared/src/NAMD_Git-2021-10-05_Source/Linux-x86_64-ofi-smp-icc$
WallClock: 0.064102  CPUTime: 0.028695  Memory: 458.476562 MB
</pre></div>
</div>
<p>The OFI binaries use less memory than the MPI versions.
The SMP versions use less memory than the non-SMP versions but the difference is lower compared with the OFI vs MPI binaries.</p>
</div>
<div class="section" id="script-summarizing-compilation-of-namd">
<h2>Script summarizing compilation of NAMD<a class="headerlink" href="#script-summarizing-compilation-of-namd" title="Permalink to this headline">¶</a></h2>
<p>The next script execute all steps above:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash

VERSION=2021-10-06

if [ ! -f NAMD_Git-${VERSION}_Source.tar.gz ]
then
wget https://www.ks.uiuc.edu/Research/namd/cvs/download/741376/NAMD_Git-${VERSION}_Source.tar.gz
fi

if  [ ! -d NAMD_Git-${VERSION}_Source ]
then
    tar -zxvf NAMD_Git-${VERSION}_Source.tar.gz
fi

cd NAMD_Git-${VERSION}_Source/
if  [ ! -d charm-6.10.2 ]
then
    tar -xvf charm-6.10.2.tar
fi
cd charm-6.10.2

MPICXX=mpiicpc ./build charm++ mpi-linux-x86_64 mpicxx ifort -j12 --with-production
MPICXX=mpiicpc ./build charm++ mpi-linux-x86_64 mpicxx ifort smp -j12 --with-production
./build charm++ ofi-linux-x86_64 icc ifort -j12 --with-production
./build charm++ ofi-linux-x86_64 icc ifort smp -j12 --with-production

cd mpi-linux-x86_64-ifort-mpicxx/tests/charm++
make clean &amp;&amp; make &amp;&amp; cd megatest &amp;&amp; make &amp;&amp; make test
cd ../../../..
cd mpi-linux-x86_64-ifort-smp-mpicxx/tests/charm++
make clean &amp;&amp; make &amp;&amp; cd megatest &amp;&amp; make &amp;&amp; make test
cd ../../../..
cd ofi-linux-x86_64-ifort-smp-icc/tests/charm++
make clean &amp;&amp; make &amp;&amp; cd megatest &amp;&amp; make &amp;&amp; make test
cd ../../../..
cd ofi-linux-x86_64-ifort-icc/tests/charm++
make clean &amp;&amp; make &amp;&amp; cd megatest &amp;&amp; make &amp;&amp; make test
cd ../../../..
cd ofi-linux-x86_64-ifort-smp-icc/tests/charm++
make clean &amp;&amp; make &amp;&amp; cd megatest &amp;&amp; make &amp;&amp; make test
cd ../../../..

cd ..

wget http://www.ks.uiuc.edu/Research/namd/libraries/fftw-linux-x86_64.tar.gz
tar xzf fftw-linux-x86_64.tar.gz
mv linux-x86_64 fftw
wget http://www.ks.uiuc.edu/Research/namd/libraries/tcl8.5.9-linux-x86_64.tar.gz
wget http://www.ks.uiuc.edu/Research/namd/libraries/tcl8.5.9-linux-x86_64-threaded.tar.gz
tar xzf tcl8.5.9-linux-x86_64.tar.gz
tar xzf tcl8.5.9-linux-x86_64-threaded.tar.gz
mv tcl8.5.9-linux-x86_64 tcl
mv tcl8.5.9-linux-x86_64-threaded tcl-threaded

ln -s charm-6.10.2 charm

cat &lt;&lt; EOF &gt; arch/Linux-x86_64-mpi-mpicxx.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = mpi-linux-x86_64-ifort-mpicxx

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF

cat &lt;&lt; EOF &gt; arch/Linux-x86_64-mpi-smp-mpicxx.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = mpi-linux-x86_64-ifort-smp-mpicxx

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF

cat &lt;&lt; EOF &gt; arch/Linux-x86_64-ofi-icc.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = ofi-linux-x86_64-ifort-icc

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF

cat &lt;&lt; EOF &gt; arch/Linux-x86_64-ofi-smp-icc.arch
NAMD_ARCH = Linux-x86_64
CHARMARCH = ofi-linux-x86_64-ifort-smp-icc

FLOATOPTS = -ip -axSKYLAKE-AVX512,CASCADELAKE -qopenmp-simd

CXX = icpc -std=c++11
CXXOPTS = -O2 \$(FLOATOPTS)
CXXNOALIASOPTS = -O2 -fno-alias \$(FLOATOPTS)
CXXCOLVAROPTS = -O2 -ip

CC = icc
COPTS = -O2 \$(FLOATOPTS)
EOF

./config Linux-x86_64-mpi-mpicxx --charm-arch mpi-linux-x86_64-ifort-mpicxx
./config Linux-x86_64-mpi-smp-mpicxx --charm-arch mpi-linux-x86_64-ifort-smp-mpicxx
./config Linux-x86_64-ofi-icc --charm-arch ofi-linux-x86_64-ifort-icc
./config Linux-x86_64-ofi-smp-icc --charm-arch ofi-linux-x86_64-ifort-smp-icc

cd Linux-x86_64-mpi-mpicxx
make -j12
cd ..
cd Linux-x86_64-mpi-smp-mpicxx
make -j12
cd ..
cd Linux-x86_64-ofi-icc
make -j12
cd ..
cd Linux-x86_64-ofi-smp-icc
make -j12
cd ..

execstack -c Linux-x86_64-*/namd2

cd Linux-x86_64-mpi-mpicxx
./charmrun ++local +p2 ./namd2 src/alanin
make release
cd ..

cd Linux-x86_64-mpi-smp-mpicxx
./charmrun ++local +p2 ./namd2 src/alanin ++ppn2
make release
cd ..

cd Linux-x86_64-ofi-icc
./charmrun ++local +p2 ./namd2 src/alanin
make release
cd ..

cd Linux-x86_64-ofi-smp-icc
./charmrun ++local +p2 ./namd2 src/alanin ++ppn2 +setcpuaffinity
make release
cd ..
</pre></div>
</div>
</div>
<div class="section" id="benchmarking-namd2">
<h2>Benchmarking NAMD2<a class="headerlink" href="#benchmarking-namd2" title="Permalink to this headline">¶</a></h2>
<p>NAMD has a case often used for Benchmarking. Still small but we can start extracting some performance figures.
ApoA1 benchmark (92,224 atoms, periodic; 2fs timestep with rigid bonds, 12A cutoff with PME every 2 steps):</p>
<p>Download the code with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">ks</span><span class="o">.</span><span class="n">uiuc</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">Research</span><span class="o">/</span><span class="n">namd</span><span class="o">/</span><span class="n">utilities</span><span class="o">/</span><span class="n">apoa1</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">tar</span> <span class="n">xzf</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
</pre></div>
</div>
<p>Once you have untar the package. Edit the input file and change the line for the output. You can do that from the command line with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">apoa1</span>
<span class="n">cp</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd_BKP</span>
<span class="n">cat</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd_BKP</span> <span class="o">|</span> <span class="n">sed</span> <span class="s1">&#39;s/\/usr//g&#39;</span> <span class="o">&gt;</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span>
</pre></div>
</div>
<p>We start with a simple execution using 12 cores. Notice that the first time you execute NAMD it will compute the FFT optimization and that could take a several seconds. With 12 cores the simulation last for around a minute:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span>
<span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span>
</pre></div>
</div>
<p>At the end of the second run the timing was:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">32.377525</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">32.377525</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">2932.089844</span> <span class="n">MB</span>
<span class="p">[</span><span class="n">Partition</span> <span class="mi">0</span><span class="p">][</span><span class="n">Node</span> <span class="mi">0</span><span class="p">]</span> <span class="n">End</span> <span class="n">of</span> <span class="n">program</span>
</pre></div>
</div>
<p>The second version with MPI and SMP is like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span> <span class="o">++</span><span class="n">ppn2</span>
<span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">mpi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">mpicxx</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span> <span class="o">++</span><span class="n">ppn2</span>
</pre></div>
</div>
<p>The timing for this version is similar:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">29.577475</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">29.438684</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">2853.781250</span> <span class="n">MB</span>
<span class="p">[</span><span class="n">Partition</span> <span class="mi">0</span><span class="p">][</span><span class="n">Node</span> <span class="mi">0</span><span class="p">]</span> <span class="n">End</span> <span class="n">of</span> <span class="n">program</span>
</pre></div>
</div>
<p>The OFI versions run like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span>
<span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span>
</pre></div>
</div>
<p>With timings for the second run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">33.552193</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">33.414692</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">662.109375</span> <span class="n">MB</span>
<span class="p">[</span><span class="n">Partition</span> <span class="mi">0</span><span class="p">][</span><span class="n">Node</span> <span class="mi">0</span><span class="p">]</span> <span class="n">End</span> <span class="n">of</span> <span class="n">program</span>
</pre></div>
</div>
<p>The final binary is OFI with SMP enabled:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span> <span class="o">++</span><span class="n">ppn2</span>
<span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">charmrun</span> <span class="o">+</span><span class="n">p12</span> <span class="o">../</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">ofi</span><span class="o">-</span><span class="n">smp</span><span class="o">-</span><span class="n">icc</span><span class="o">/</span><span class="n">namd2</span> <span class="n">apoa1</span><span class="o">.</span><span class="n">namd</span> <span class="o">++</span><span class="n">ppn2</span>
</pre></div>
</div>
<p>With timings:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">34.350666</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">34.264492</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">641.882812</span> <span class="n">MB</span>
<span class="p">[</span><span class="n">Partition</span> <span class="mi">0</span><span class="p">][</span><span class="n">Node</span> <span class="mi">0</span><span class="p">]</span> <span class="n">End</span> <span class="n">of</span> <span class="n">program</span>
</pre></div>
</div>
<p>At this point all four binaries perform very similarly. However, this execution was done on the head node, where several user and system processes could be taking CPU time, making any claim about performance misleading.</p>
<p>Our next step is to move the execution to an isolated compute node where the time could be more accurate.</p>
<p>To do this lets request an interactive execution on an isolated node:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">qsub</span> <span class="o">-</span><span class="n">I</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">l</span> <span class="n">nodes</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span><span class="n">ppn</span><span class="o">=</span><span class="mi">40</span>
</pre></div>
</div>
<p>Once you log into the compute node, load clean your modules and load the Intel Compilers 2021:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">purge</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">compiler</span><span class="o">/</span><span class="mf">2021.2</span><span class="o">.</span><span class="mi">0</span> <span class="n">mpi</span><span class="o">/</span><span class="mf">2021.2</span><span class="o">.</span><span class="mi">0</span> <span class="n">mkl</span><span class="o">/</span><span class="mf">2021.2</span><span class="o">.</span><span class="mi">0</span>
</pre></div>
</div>
<p>The following script can be used to execute 4 versions of NAMD under the same conditions multiple times to gather a more precise timing.
The first execution will be larger due to NAMD computing the FFT parameter optimization.
The script could be called <code class="docutils literal notranslate"><span class="pre">run_apoa1.sh</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash

for j in 2 4 8 10 20 40
do

for i in 0 1 2 3
do

echo Linux-x86_64-mpi-mpicxx ${j} ${i}
../Linux-x86_64-mpi-mpicxx/charmrun +p$j \
    ../Linux-x86_64-mpi-mpicxx/namd2 apoa1.namd &gt; mpi_${j}_${i}.dat
echo Linux-x86_64-mpi-smp-mpicxx ${j} ${i}
../Linux-x86_64-mpi-smp-mpicxx/charmrun +p$j \
    ../Linux-x86_64-mpi-smp-mpicxx/namd2 apoa1.namd ++ppn2 &gt; mpi_smp_${j}_${i}.dat
echo Linux-x86_64-ofi-icc ${j} ${i}
../Linux-x86_64-ofi-icc/charmrun +p$j \
    ../Linux-x86_64-ofi-icc/namd2 apoa1.namd &gt; ofi_${j}_${i}.dat
echo Linux-x86_64-ofi-smp-icc ${j} ${i}
../Linux-x86_64-ofi-smp-icc/charmrun +p$j \
    ../Linux-x86_64-ofi-smp-icc/namd2 apoa1.namd ++ppn2 +setcpuaffinity &gt; ofi_smp_${j}_${i}.dat

done

done
</pre></div>
</div>
<p>The script can be executed like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">run_apoa1</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>&lt;!–</p>
<p>The timings are stored on the output of each execution and can be extracted like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">40</span><span class="n">core_mpi_smp_10_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">155.227570</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">123.259064</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4688.945312</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_10_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">155.695709</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">123.160561</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4676.308594</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_10_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">155.656311</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">122.411018</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4669.125000</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_10_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">155.610092</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">123.485626</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4674.390625</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_20_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">149.466599</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">121.044876</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">6597.683594</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_20_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">150.627670</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">121.731064</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">6579.105469</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_20_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">151.018372</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">121.831726</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">6570.664062</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_20_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">150.703796</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">120.617912</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">6580.136719</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_2_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">304.661163</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">165.003647</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4063.429688</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_2_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">261.148773</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">127.608749</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4061.234375</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_2_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">267.194000</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">125.475502</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4048.324219</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_2_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">263.977295</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">128.551437</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4067.074219</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_40_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">136.069626</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">124.950996</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">8210.808594</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_40_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">136.036179</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">125.778336</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">8210.804688</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_40_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">136.111237</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">123.779816</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">8210.804688</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_40_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">136.662827</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">126.436882</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">8211.011719</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_5_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">170.709076</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">121.197380</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4060.437500</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_5_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">170.846603</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">122.806618</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4060.964844</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_5_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">170.953751</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">122.650635</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4060.734375</span> <span class="n">MB</span>
<span class="mi">40</span><span class="n">core_mpi_smp_5_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">171.682648</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">122.736526</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4060.371094</span> <span class="n">MB</span>
<span class="n">mpi_120_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">97.641594</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">97.641594</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4637.144531</span> <span class="n">MB</span>
<span class="n">mpi_120_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">56.845337</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">56.845337</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4641.140625</span> <span class="n">MB</span>
<span class="n">mpi_120_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">57.044777</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">57.044777</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4639.140625</span> <span class="n">MB</span>
<span class="n">mpi_120_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">57.095589</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">57.095585</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4639.140625</span> <span class="n">MB</span>
<span class="n">mpi_160_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">87.904030</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">87.904030</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4673.871094</span> <span class="n">MB</span>
<span class="n">mpi_160_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">47.383121</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">47.383121</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4640.863281</span> <span class="n">MB</span>
<span class="n">mpi_160_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">87.837677</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">87.837677</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4631.820312</span> <span class="n">MB</span>
<span class="n">mpi_160_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">47.469536</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">47.469536</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4638.867188</span> <span class="n">MB</span>
<span class="n">mpi_200_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">81.231453</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">81.231453</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4639.152344</span> <span class="n">MB</span>
<span class="n">mpi_200_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">40.415939</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">40.415939</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4612.089844</span> <span class="n">MB</span>
<span class="n">mpi_200_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">40.618484</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">40.618484</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4614.089844</span> <span class="n">MB</span>
<span class="n">mpi_200_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">40.277576</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">40.277576</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4680.089844</span> <span class="n">MB</span>
<span class="n">mpi_20_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">254.534271</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">254.534271</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">3908.117188</span> <span class="n">MB</span>
<span class="n">mpi_20_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">206.488068</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">206.488068</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">3907.054688</span> <span class="n">MB</span>
<span class="n">mpi_20_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">206.536240</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">206.536240</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">3908.660156</span> <span class="n">MB</span>
<span class="n">mpi_20_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">206.065628</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">206.065628</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">3852.343750</span> <span class="n">MB</span>
<span class="n">mpi_40_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">150.173309</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">150.173309</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4824.882812</span> <span class="n">MB</span>
<span class="n">mpi_40_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">136.239975</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">136.239975</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4822.230469</span> <span class="n">MB</span>
<span class="n">mpi_40_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">136.077591</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">136.077591</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4824.234375</span> <span class="n">MB</span>
<span class="n">mpi_40_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">135.873062</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">135.873062</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4822.234375</span> <span class="n">MB</span>
<span class="n">mpi_80_0</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">121.231468</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">121.231468</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4637.136719</span> <span class="n">MB</span>
<span class="n">mpi_80_1</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">79.989479</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">79.989479</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4637.136719</span> <span class="n">MB</span>
<span class="n">mpi_80_2</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">80.023216</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">80.023216</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4635.136719</span> <span class="n">MB</span>
<span class="n">mpi_80_3</span><span class="o">.</span><span class="n">dat</span><span class="p">:</span><span class="n">WallClock</span><span class="p">:</span> <span class="mf">80.146004</span>  <span class="n">CPUTime</span><span class="p">:</span> <span class="mf">80.146004</span>  <span class="n">Memory</span><span class="p">:</span> <span class="mf">4639.136719</span> <span class="n">MB</span>
</pre></div>
</div>
<p>–&gt;</p>
<p>These preliminar results shows and small advantage for the non-smp versions over the smp builds. More important, the OFI versions have much smaller memory utilization which could be of relevance for large executions.</p>
<div class="figure">
<img alt="apoa1_bench.png" src="../_images/apoa1_bench.png" />
</div>
<p>From the figure above we can see that the MPI versions consume more memory as we increase the number of cores.
The scaling is computed based on the calculation for 2 cores as reference.
Notice that there is an small advantage for the non-SMP versions (MPI and OFI) and with a high penalty for the 40 core case with scaling under 25%.</p>
<p>More significant for measuring the performance of NAMD for large systems comes from the STMV benchmark (1,066,628 atoms, periodic; 2fs timestep with rigid bonds, 12A cutoff with PME every 2 steps)</p>
<p>Download the input for the STMV benchmark, untar and uncompress the package and move into the folder:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">ks</span><span class="o">.</span><span class="n">uiuc</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">Research</span><span class="o">/</span><span class="n">namd</span><span class="o">/</span><span class="n">utilities</span><span class="o">/</span><span class="n">stmv</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">tar</span> <span class="o">-</span><span class="n">zxvf</span> <span class="n">stmv</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">cd</span> <span class="n">stmv</span>
</pre></div>
</div>
<p>The STMV execution takes longer so a submission script is better suited for the task.
Our next set of tests will explore the best performance that we can get using all the cores on a single node. There are several options for the SMP case either adding more worker threads (+pN) or  adding more PEs per logical node (++ppn N).</p>
<p>The first set of benchmark uses the SMP builds. Each node has 40 cores so there are several ways of balance the number of process and the number of threads on each process. The benchmarks below uses the 40 cores under a different number of
computational threads and the complementary number of processes.</p>
<p>The results show that the MPI and OFI versions are similar in CPU time but differ in wall time. That could be explained by the OFI being more efficient network I/O improving the overall time the computer needs to perform the task.
From the point of view of memory usage the OFI version shows considerably better memory usage.</p>
<div class="figure">
<img alt="stmv_walltime.png" src="../_images/stmv_wallclock_smp.png" />
</div>
<div class="figure">
<img alt="stmv_cputime.png" src="../_images/stmv_cputime_smp.png" />
</div>
<div class="figure">
<img alt="stmv_memory.png" src="../_images/stmv_memory_smp.png" />
</div>
<p>For the case of single thread NAMD builds the benchmarks show that the OFI and MPI flavors behave similar in terms of performance with an small advantage for OFI due to a better communication between nodes compared to the MPI build.
The big advantage comes from the memory usage, the OFI build uses less than half memory compared to MPI build.</p>
<div class="figure">
<img alt="stmv_walltime.png" src="../_images/stmv_wallclock_ncores.png" />
</div>
<div class="figure">
<img alt="stmv_cputime.png" src="../_images/stmv_cputime_ncores.png" />
</div>
<div class="figure">
<img alt="stmv_memory.png" src="../_images/stmv_memory_ncores.png" />
</div>
</div>
<div class="section" id="conclusions">
<h2>Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">¶</a></h2>
<p>We have explore the performance of NAMD using two flavors of network communication both for single thread and SMP build. The benchmarks using STMV (1 million atoms) shows an small advantage for OFI in most cases. However, it it differentiate notably on its memory usage, something that could be critical for systems with large number of atoms.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="610.DFT.html" class="btn btn-neutral float-right" title="Density Functional Theory" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="608.ForceFields.html" class="btn btn-neutral float-left" title="Force Field Molecular Dynamics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, West Virginia University

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>