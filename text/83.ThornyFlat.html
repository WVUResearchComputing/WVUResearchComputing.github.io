

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Thorny Flat (2019-) &mdash; WVU-RC 2023.04.03 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Dolly Sods (2023-)" href="84.DollySods.html" />
    <link rel="prev" title="Spruce Knob (2018-2023)" href="82.Spruce.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> WVU-RC
          

          
            
            <img src="../_static/ResearchComputing.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                2023.04
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="10.Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="20.QuickStart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="30.BasicUsage.html">Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="40.AdvancedUsage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="500.ScientificProgramming.html">Scientific Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="600.SoftAdmin.html">Software Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="700.DomainSpecific.html">Domain Specific Details</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="80.ClusterSpecific.html">Clusters Specifications</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="81.Mountaineer.html">Mountaineer (2013-2018)</a></li>
<li class="toctree-l2"><a class="reference internal" href="82.Spruce.html">Spruce Knob (2018-2023)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Thorny Flat (2019-)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#acknowledgment-message">Acknowledgment Message</a></li>
<li class="toctree-l4"><a class="reference internal" href="#total-compute-resources">Total Compute Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shared-interconnect">Shared Interconnect</a></li>
<li class="toctree-l4"><a class="reference internal" href="#resource-manager-and-system-scheduler">Resource manager and system scheduler</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hardware">Hardware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#phase-0-1-hardware">Phase 0/1 Hardware</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#partitions">Partitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#research-team-partitions">Research Team Partitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#standby-partition">Standby Partition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#community-node-partitions">Community Node Partitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hardware-acceleration">Hardware acceleration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="84.DollySods.html">Dolly Sods (2023-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="85.GoFirst.html">Go First Data-Analytics Cluster</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="90.References.html">References</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">WVU-RC</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="80.ClusterSpecific.html">Clusters Specifications</a> &raquo;</li>
        
      <li>Thorny Flat (2019-)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/text/83.ThornyFlat.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="thorny-flat-2019">
<h1>Thorny Flat (2019-)<a class="headerlink" href="#thorny-flat-2019" title="Permalink to this headline">¶</a></h1>
<p>Thorny Flat is WVU Latest HPC Cluster.  It was deployed in Feburary 2019 and funded in large part by <a class="reference external" href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1726534&amp;HistoricalAwards=false">NSF Major Research Instrumentation (MRI) Grant Award #1726534</a>. The cluster has a total of 6196 CPU cores spread over 170 nodes using a shared Intel Omnipath 100Gbps Interconnect. The system is a heterogeneous cluster in which there are different node types. In addition, each year a new addition is added to the cluster, which is known as a new phase. The cluster has five phases and currently is in phase 2.</p>
<a class="reference internal image-reference" href="../_images/ThornyFlat.jpg"><img alt="Thorny Flat" class="align-center" src="../_images/ThornyFlat.jpg" style="width: 150.0px; height: 300.0px;" /></a>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p><em>(This text can be used for proposals to Grant Funding Agencies)</em></p>
<p>Thorny Flat is a general-purpose High-Performance Computing (HPC) cluster.
Thorny Flat serves the HPC needs for West Virginia University (WVU) and other
higher education institutions in West Virginia. It is hosted in Pittsburgh
Supercomputer Center and was built thanks to NSF Major Research Instrumentation
(MRI) Grant Award #1726534</p>
<p>Thorny Flat is a cluster of 178 compute nodes plus 4 management nodes.
The total number of CPU cores is 6516.
The distribution of CPU cores is as follows:
140 compute nodes with a dual-socket Intel(R) Xeon(R) Gold 6138 or 6230 (40 cores per node).
7 compute nodes with dual-socket Intel(R) Xeon(R) Gold 6126 (24 cores per node)
27 compute nodes with dual-socket Intel(R) Xeon(R) Silver 4210 (20 cores per node).
4 compute nodes with dual-socket Intel(R) Xeon(R) Gold 6126 (52 cores per node).
Memory on compute nodes range from 96GB to 768GB.
The machines are interconnected using Intel(R) Omnipath(R) 100 Gbps with a blocking ratio of 5:1.</p>
<p>Thorny Flat has 11 compute nodes with hardware accelerators in the form of NVIDIA GPUs.
There is a total of 47 GPU cards distributed as follows:
7 compute nodes with 3 GPUs NVIDIA(R) Quadro P6000 24GB PCIe GPUs.
3 compute nodes with 8 GPUs NVIDIA(R) Quadro RTX 6000 24GB PCIe GPUs.
1 compute node with 2 GPUs NVIDIA(R) A100 40GB PCIe GPUs.</p>
<p>Thorny Flat scored 115 TeraFLOPS using 101 CPU-only compute nodes.
Score was measured from the HPL Linpack benchmark.</p>
<p>Thorny Flat uses SLURM for workload managment and it has a variety of compilers,
numerical libraries and scientific software specifically compiled and optimized for the hardware architecture.</p>
<section id="acknowledgment-message">
<h3>Acknowledgment Message<a class="headerlink" href="#acknowledgment-message" title="Permalink to this headline">¶</a></h3>
<p>We ask our users to acknowledge the use of Thorny Flat in all publications that were possible thanks to the use of this resource. The message on the acknowledgment section could be as follows:</p>
<blockquote>
<div><p><em>Computational resources were provided by the WVU Research Computing Thorny Flat HPC cluster, which is funded in part by NSF OAC-1726534.</em></p>
</div></blockquote>
</section>
<section id="total-compute-resources">
<h3>Total Compute Resources<a class="headerlink" href="#total-compute-resources" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>6516 CPU Cores</p></li>
<li><p>178 Compute nodes
* 167 CPU-only Compute nodes
* 7 Hardware-accelerated compute nodes with 3 NVIDIA P6000 (21 GPU cards)
* 3 Hardware-accelerated compute nodes with 8 NVIDIA RTX6000 (24 GPU cards)
* 1 Hardware-accelerated compute node with 2 NVIDIA A100</p></li>
<li><p>4 Management Nodes</p></li>
</ul>
</div></blockquote>
</section>
<section id="shared-interconnect">
<h3>Shared Interconnect<a class="headerlink" href="#shared-interconnect" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>Intel(R) Omnipath(R) 100 Gbps with a blocking ratio of 5:1</p></li>
</ul>
</div></blockquote>
</section>
<section id="resource-manager-and-system-scheduler">
<h3>Resource manager and system scheduler<a class="headerlink" href="#resource-manager-and-system-scheduler" title="Permalink to this headline">¶</a></h3>
<p>Thorny Flat uses SLURM as workload manager version 22.05.6.</p>
</section>
</section>
<section id="hardware">
<h2>Hardware<a class="headerlink" href="#hardware" title="Permalink to this headline">¶</a></h2>
<section id="phase-0-1-hardware">
<h3>Phase 0/1 Hardware<a class="headerlink" href="#phase-0-1-hardware" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://ark.intel.com/content/www/us/en/ark/products/120476/intel-xeon-gold-6138-processor-27-5m-cache-2-00-ghz.html">Intel® Xeon® Gold 6138 Processor</a></p></li>
<li><p><a class="reference external" href="https://ark.intel.com/content/www/us/en/ark/products/120483/intel-xeon-gold-6126-processor-19-25m-cache-2-60-ghz.html">Intel® Xeon® Gold 6126 Processor</a></p></li>
</ul>
</div></blockquote>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 56%" />
<col style="width: 13%" />
<col style="width: 9%" />
<col style="width: 7%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Node Type</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><div class="line-block">
<div class="line">Community</div>
<div class="line">Nodes</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Condo</div>
<div class="line">Nodes</div>
</div>
</th>
<th class="head"><p>Total</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Small Memory</p></td>
<td><ul class="simple">
<li><p>2 x Intel® Xeon® Gold 6138 Processor (20 cores/cpu)</p></li>
<li><p>96GB memory</p></li>
<li><p>240GB SSD</p></li>
<li><p>100 Gb Omnipath</p></li>
<li><p>5 yr warranty</p></li>
</ul>
</td>
<td><p>64</p></td>
<td><p>13</p></td>
<td><p>77</p></td>
</tr>
<tr class="row-odd"><td><p>Medium Memory</p></td>
<td><ul class="simple">
<li><p>2 x Intel® Xeon® Gold 6138 Processor (20 cores/cpu)</p></li>
<li><p>192GB memory</p></li>
<li><p>240GB SSD</p></li>
<li><p>100 Gb Omnipath</p></li>
<li><p>5 yr warranty</p></li>
</ul>
</td>
<td><p>0</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-even"><td><p>Large Memory</p></td>
<td><ul class="simple">
<li><p>2 x Intel® Xeon® Gold 6138 Processor (20 cores/cpu)</p></li>
<li><p>384GB memory</p></li>
<li><p>240GB SSD</p></li>
<li><p>100 Gb Omnipath</p></li>
<li><p>5 yr warranty</p></li>
</ul>
</td>
<td><p>0</p></td>
<td><p>4</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd"><td><p>XL Memory</p></td>
<td><ul class="simple">
<li><p>2 x Intel® Xeon® Gold 6138 Processor (20 cores/cpu)</p></li>
<li><p>768GB memory</p></li>
<li><p>240GB SSD</p></li>
<li><p>100 Gb Omnipath</p></li>
<li><p>5 yr warranty</p></li>
</ul>
</td>
<td><p>3</p></td>
<td><p>1</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even"><td><p>GPU</p></td>
<td><ul class="simple">
<li><p>2 x Intel® Xeon® Gold 6126 Processor (12 cores/cpu)</p></li>
<li><p>3 x NVIDIA Quadro P6000 24GB PCIe GPUs,</p></li>
<li><p>96GB memory</p></li>
<li><p>240GB SSD</p></li>
<li><p>100 Gb Omnipath</p></li>
<li><p>5 yr warranty</p></li>
</ul>
</td>
<td><p>6</p></td>
<td><p>1</p></td>
<td><p>7</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="partitions">
<h2>Partitions<a class="headerlink" href="#partitions" title="Permalink to this headline">¶</a></h2>
<p>The current state and limits of partitions can be found using the qstat
command.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">server</span><span class="p">:</span> <span class="n">trcis002</span><span class="o">.</span><span class="n">hpc</span><span class="o">.</span><span class="n">wvu</span><span class="o">.</span><span class="n">edu</span>

<span class="n">Partition</span>            <span class="n">Memory</span> <span class="n">CPU</span> <span class="n">Time</span> <span class="n">Walltime</span> <span class="n">Node</span>  <span class="n">Run</span> <span class="n">Que</span> <span class="n">Lm</span>  <span class="n">State</span>
<span class="o">----------------</span> <span class="o">------</span> <span class="o">--------</span> <span class="o">--------</span> <span class="o">----</span>  <span class="o">---</span> <span class="o">---</span> <span class="o">--</span>  <span class="o">-----</span>
<span class="n">standby</span>            <span class="o">--</span>      <span class="o">--</span>    <span class="mi">04</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>   <span class="o">--</span>    <span class="mi">0</span>   <span class="mi">0</span> <span class="o">--</span>   <span class="n">E</span> <span class="n">R</span>
<span class="n">comm_small_week</span>    <span class="o">--</span>      <span class="o">--</span>    <span class="mi">168</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">0</span>   <span class="o">--</span>    <span class="mi">0</span>   <span class="mi">0</span> <span class="o">--</span>   <span class="n">E</span> <span class="n">R</span>
<span class="n">comm_small_day</span>     <span class="o">--</span>      <span class="o">--</span>    <span class="mi">24</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span>   <span class="o">--</span>    <span class="mi">0</span>   <span class="mi">0</span> <span class="o">--</span>   <span class="n">E</span> <span class="n">R</span>
<span class="n">comm_gpu_week</span>      <span class="o">--</span>      <span class="o">--</span>    <span class="mi">168</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">0</span>   <span class="o">--</span>    <span class="mi">0</span>   <span class="mi">0</span> <span class="o">--</span>   <span class="n">E</span> <span class="n">R</span>
<span class="n">comm_xl_week</span>       <span class="o">--</span>      <span class="o">--</span>    <span class="mi">168</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">0</span>   <span class="o">--</span>    <span class="mi">0</span>   <span class="mi">0</span> <span class="o">--</span>   <span class="n">E</span> <span class="n">R</span>
                                           <span class="o">-----</span> <span class="o">-----</span>
                                                  <span class="mi">0</span>     <span class="mi">0</span>
</pre></div>
</div>
<p>There are three main partition types - research team partitions, the standby partition, and community node partitions.</p>
</section>
<section id="research-team-partitions">
<h2>Research Team Partitions<a class="headerlink" href="#research-team-partitions" title="Permalink to this headline">¶</a></h2>
<p>Research teams that have bought their own compute nodes have private partitions that link all their compute nodes together. Only users given permission from the research team’s buyer (Usually the labs PI) will have permission to directly submit jobs to these partitions. While these are private partitions - unused resources/compute nodes from these partitions will be available to the standby partition (see below). However, per the system-wide policies, all research team’s compute nodes must be available to the research team’s users within 4 hours of job submission.  By default, these partitions are regulated by first come, first serve queuing. However, individual research teams can ask for different settings for their respective partition, and should <a class="reference external" href="GettingHelp">contact</a> the RC HPC team with these requests.</p>
</section>
<section id="standby-partition">
<h2>Standby Partition<a class="headerlink" href="#standby-partition" title="Permalink to this headline">¶</a></h2>
<p>The standy partition is for using resources from research teams partitions that are not currently being used. Priority on the standby partition is set by fair share queuing. This means that user priority is assigned based on a combination of the size of the job and how much system resources the user have used during the given week, with higher priority assigned to larger jobs and/or user jobs that have used fewer system resources in the week. Further, the standby partition has a 4 hour wall time.</p>
</section>
<section id="community-node-partitions">
<h2>Community Node Partitions<a class="headerlink" href="#community-node-partitions" title="Permalink to this headline">¶</a></h2>
<p>Thorny Flat has several partitions that start with the word ‘comm’. These partitions are linked to the 73 compute/GPU nodes bought using NSF funding sources, and as such is open for Statewide Higher Education use, hardware/resource information can be found on the <a class="reference external" href="Systems_Spruce">Thorny Flat Systems page</a> These partitions are separated by node type (i.e.  extra large memory, and gpu) and can be used by all users. Currently, these nodes are regulated by fair share queuing. This means that user priority is assigned based on a combination of the size of the job and how much system resources the user have used during the given week, with higher priority assigned to larger jobs and/or user jobs that have used less system resources in the week. Further, all community partitions have a week wall time, except for the (comm_small_day). comm_small_day allows jobs up 24 hours; and, this partition class has access to a larger number of resources than than comm_small_week). These restrictions are set to prevent a single user occupying a large number of the community resources for an excessively long time.</p>
</section>
<section id="hardware-acceleration">
<h2>Hardware acceleration<a class="headerlink" href="#hardware-acceleration" title="Permalink to this headline">¶</a></h2>
<p>Thorny Flat has 11 compute nodes with hardware accelerators in the form of NVIDIA GPU cards.
The GPUs present on Thorny Flat are NVIDIA P6000, NVIDIA QUADRO RTX6000 and NVIDIA A100
The following table describes the distribution of accelerators in the GPU compute nodes.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 49%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Node Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><div class="line-block">
<div class="line">Quadro</div>
<div class="line">P6000</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Quadro</div>
<div class="line">RTX 6000</div>
</div>
</th>
<th class="head"><p>A100</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>tcogq001</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6126 CPU &#64; 2.60GHz</div>
<div class="line">Total RAM: 96GB</div>
</div>
</td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>tcogq002</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6126 CPU &#64; 2.60GHz</div>
<div class="line">Total RAM: 96GB</div>
</div>
</td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>tcogq003</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6126 CPU &#64; 2.60GHz</div>
<div class="line">Total RAM: 96GB</div>
</div>
</td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>tcogq004</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6126 CPU &#64; 2.60GHz</div>
<div class="line">Total RAM: 96GB</div>
</div>
</td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>tcogq005</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6126 CPU &#64; 2.60GHz</div>
<div class="line">Total RAM: 96GB</div>
</div>
</td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>tcogq006</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6126 CPU &#64; 2.60GHz</div>
<div class="line">Total RAM: 96GB</div>
</div>
</td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>tbmgq001</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6126 CPU &#64; 2.60GHz</div>
<div class="line">Total RAM: 96GB</div>
</div>
</td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>tbmgq100</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6230R CPU &#64; 2.10GHz</div>
<div class="line">Total RAM: 192GB</div>
</div>
</td>
<td><p>0</p></td>
<td><p>8</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>tbegq201</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6230R CPU &#64; 2.10GHz</div>
<div class="line">Total RAM: 192GB</div>
</div>
</td>
<td><p>0</p></td>
<td><p>8</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>tbegq202</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6230R CPU &#64; 2.10GHz</div>
<div class="line">Total RAM: 192GB</div>
</div>
</td>
<td><p>0</p></td>
<td><p>8</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>tbegq200</p></td>
<td><div class="line-block">
<div class="line">2x Intel(R) Xeon(R) Gold 6230R CPU &#64; 2.10GHz</div>
<div class="line">Total RAM: 192GB</div>
</div>
</td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>TOTAL</p></td>
<td><div class="line-block">
<div class="line">CPU: 7 x 24 cores + 4 x 52 cores = 376 cores</div>
<div class="line">RAM: 7 x 96GB + 4 x 192GB = 1440 GB</div>
</div>
</td>
<td><p>21</p></td>
<td><p>24</p></td>
<td><p>2</p></td>
</tr>
</tbody>
</table>
<p>The specifications of the three kinds of GPU cards on Thorny Flat are shown in the table below</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 19%" />
<col style="width: 18%" />
<col style="width: 16%" />
<col style="width: 11%" />
<col style="width: 18%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><div class="line-block">
<div class="line">GPU Card</div>
<div class="line">Model</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">GPU</div>
<div class="line">Memory</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">CUDA</div>
<div class="line">Cores</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Tensor</div>
<div class="line">Cores</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Max Power</div>
<div class="line">Compsumption</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Compute</div>
<div class="line">Capability</div>
</div>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Quadro P6000</p></td>
<td><p>24 GB GDDR5X</p></td>
<td><p>3840</p></td>
<td></td>
<td><p>250 W</p></td>
<td><p>6.1</p></td>
</tr>
<tr class="row-odd"><td><p>Quadro RTX 6000</p></td>
<td><p>24 GB GDDR6</p></td>
<td><p>4608</p></td>
<td><p>576</p></td>
<td><p>250 W</p></td>
<td><p>7.5</p></td>
</tr>
<tr class="row-even"><td><p>A100-PCIE-40GB</p></td>
<td><p>40 GB HBM2</p></td>
<td><div class="line-block">
<div class="line">6912 FP32</div>
<div class="line">3456 FP64</div>
</div>
</td>
<td><p>432</p></td>
<td><p>250 W</p></td>
<td><p>8.0</p></td>
</tr>
</tbody>
</table>
<p>Full specifications for the GPU cards can be found for <a class="reference external" href="https://images.nvidia.com/content/pdf/quadro/data-sheets/192152-NV-DS-Quadro-P6000-US-12Sept-NV-FNL-WEB.pdf">Quadro P6000</a> , <a class="reference external" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/quadro-product-literature/quadro-rtx-6000-us-nvidia-704093-r4-web.pdf">Quadro RTX 6000</a> and <a class="reference external" href="https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf">NVIDIA A100</a></p>
<p>The GPUs in Thorny Flat have different compute capabilities.
The compute capability of a device is represented by a version number, also sometimes called its “SM version”.
This version number identifies the features supported by the GPU hardware and is used by applications at runtime to determine which hardware features and/or instructions are available on the present GPU.</p>
<p>The compute capability comprises a major revision number X and a minor revision number Y and is denoted by X.Y.</p>
<p>Devices with the same major revision number are of the same core architecture.
The major revision number is 8 is for devices based on the NVIDIA Ampere GPU architecture (like A100), 7 for devices based on the Volta architecture (like the Quadro RTX 6000), and 6 for devices based on the Pascal architecture (like the Quadro P6000).</p>
<p>You can see <a class="reference external" href="https://developer.nvidia.com/cuda-gpus">Compute Capabilities</a> for other GPU cards.</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="84.DollySods.html" class="btn btn-neutral float-right" title="Dolly Sods (2023-)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="82.Spruce.html" class="btn btn-neutral float-left" title="Spruce Knob (2018-2023)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, West Virginia University

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>